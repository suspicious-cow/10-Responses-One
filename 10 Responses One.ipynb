{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Responses One\n",
    "\n",
    "## Basic Connection and Packages\n",
    "\n",
    "### Importing OpenAI and Initializing the Client\n",
    "\n",
    "To begin, we'll import the `OpenAI` class from the `openai` library, which allows us to interact with the OpenAI API. Next, we initialize a client instance, which we'll use to send requests and receive responses from the OpenAI models.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This script is a simple example of using the OpenAI API\n",
    "It uses the OpenAI Python client library to open a connection to the OpenAI API.\n",
    "This also looks for the OPENAI_API_KEY environment variable to authenticate the client.\n",
    "\"\"\"\n",
    "from openai import OpenAI\n",
    "client = OpenAI()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Additional Libraries\n",
    "\n",
    "Next, we import the `json` library. This standard Python library helps us handle JSON data, allowing easy conversion between JSON strings and Python data structures.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Additional imports\n",
    "These imports are used for various purposes in the script.\n",
    "\"\"\"\n",
    "\n",
    "import json # common library for working with JSON data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Messages\n",
    "\n",
    "### Creating a Chat Completion with OpenAI API\n",
    "\n",
    "Now, we'll demonstrate how to use the OpenAI API to generate text completions. We'll utilize the previously initialized client to send a prompt to the `gpt-4o-mini` model—a compact variant of the GPT-4 model optimized for efficient performance. \n",
    "\n",
    "In this example, we define two roles with messages within our prompt:\n",
    "\n",
    "- **System**: Sets the behavior of the model, instructing it to act as a helpful assistant.\n",
    "- **User**: Provides a specific request—in this case, asking the model to write a haiku about recursion in programming.\n",
    "\n",
    "After sending this prompt, we print the model's response.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lines call back to lines,  \n",
      "Looping thoughts in endless dance—  \n",
      "Code within itself.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "This script demonstrates how to use the OpenAI API to generate text completions.\n",
    "It uses the OpenAI Python client library to connection we already made to connect to the OpenAI API.\n",
    "This uses the `gpt-4o-mini` model, which is a variant of the GPT-4 model.\n",
    "The script sends a prompt to the model and prints the generated text.\n",
    "\"\"\"\n",
    "response = client.responses.create(\n",
    "  model=\"gpt-4o-mini\",\n",
    "  input=[\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Write a haiku about recursion in programming.\"}\n",
    "  ]\n",
    ")\n",
    "\n",
    "\n",
    "print(response.output_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Updating to the Newer Model Types and Message Roles\n",
    "\n",
    "In this example, we demonstrate using the newer OpenAI model `o3-mini`. Notably, this model variant introduces a new role called `developer`, replacing the previous `system` role. \n",
    "\n",
    "The updated roles are:\n",
    "\n",
    "- **Developer**: Provides instructions defining the assistant's behavior.\n",
    "- **User**: Specifies the actual query or request—in this case, generating a haiku about recursion in programming.\n",
    "\n",
    "We send these messages to the `o3-mini` model and output the generated response.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Code calls self again,  \n",
      "Echoes in digital loops,  \n",
      "Base case seals the end.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "This script demonstrates how to use the OpenAI API to generate text completions.\n",
    "It uses the OpenAI Python client library to connection we already made to connect to the OpenAI API.\n",
    "This uses the `o3-mini` model, which is a variant of the o3 model.\n",
    "The script sends a prompt to the model and prints the generated text.\n",
    "\"\"\"\n",
    "response = client.responses.create(\n",
    "  model=\"o3-mini\",\n",
    "  input=[\n",
    "    {\"role\": \"developer\", \"content\": \"You are a helpful assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Write a haiku about recursion in programming.\"}\n",
    "  ]\n",
    ")\n",
    "\n",
    "print(response.output_text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Formats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specifying the Text Format\n",
    "\n",
    "Next, we add the `text` parameter to our request, allowing explicit control over how the API returns the response. Here, we specify `\"text\"` to ensure the model's response is returned as plain text, suitable for direct use or printing.\n",
    "\n",
    "We continue to use the `gpt-4o-mini` model and the newer `developer` role to instruct the assistant's behavior.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calls within calls flow,  \n",
      "A loop of nested shadows,  \n",
      "Endless depth to know.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "This script shows how to use the OpenAI API to generate text completions.\n",
    "We add the response_format parameter to specify the format of the response.\n",
    "In this case, we want the response to be in text format.\n",
    "\"\"\"\n",
    "response = client.responses.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    input=[\n",
    "        {\"role\": \"developer\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Write a haiku about recursion in programming.\"}\n",
    "    ],\n",
    "    text={\"format\": {\"type\": \"text\"}},  \n",
    ")\n",
    "\n",
    "print(response.output_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Receiving Responses in JSON Format\n",
    "\n",
    "In this example, we demonstrate how to explicitly request the model’s response as a structured JSON object using the `text` parameter set to `\"json_object\"`. This format is particularly useful when you want to parse and integrate the model's responses programmatically into applications or data pipelines.\n",
    "\n",
    "We continue using the `gpt-4o-mini` model and clearly instruct it (via the user message) to generate the response as JSON.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"haiku\": [\n",
      "    \"A function calls self,\",\n",
      "    \"Layers fold in on each,\",\n",
      "    \"Endless depths unveil.\"\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "This script shows how to use the OpenAI API to generate text completions.\n",
    "We add the response_format parameter to specify the format of the response.\n",
    "In this case, we want the response to be in JSON object format.\n",
    "\"\"\"\n",
    "\n",
    "response = client.responses.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    input=[\n",
    "        {\"role\": \"developer\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Write a haiku about recursion in programming. Give me the response in JSON format.\"}\n",
    "    ],\n",
    "    text={\"format\": {\"type\": \"json_object\"}},  \n",
    ")\n",
    "\n",
    "print(response.output_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining Custom JSON Schema for Structured Responses\n",
    "\n",
    "In this example, we demonstrate how to obtain structured, schema-based JSON responses from the OpenAI API. We set the `text` parameter to `\"json_schema\"` and define our own schema. This custom schema precisely controls the structure and content of the generated response, making it easy to integrate into applications, databases, or analytical tools.\n",
    "\n",
    "Our custom JSON schema requests detailed, structured information about an animal—in this case, an emperor penguin—including:\n",
    "\n",
    "- **Name**: The common name of the animal.\n",
    "- **Species**: The species classification.\n",
    "- **Lifespan**: Typical lifespan in years.\n",
    "- **Minimum and Maximum Weight**: Typical weight range in kilograms.\n",
    "- **Habitat**: Natural habitat description.\n",
    "- **Diet**: Typical dietary habits.\n",
    "\n",
    "We then parse the returned JSON content into a Python dictionary and print it in a formatted, easy-to-read way.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"name\": \"Emperor Penguin\",\n",
      "  \"species\": \"Aptenodytes forsteri\",\n",
      "  \"lifespan\": 15,\n",
      "  \"min_weight\": 22,\n",
      "  \"max_weight\": 45,\n",
      "  \"habitat\": \"Antarctica and surrounding islands\",\n",
      "  \"diet\": \"Carnivorous, primarily feeds on fish, squid, and krill.\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "This script shows how to use the OpenAI API to generate text completions.\n",
    "We add the response_format parameter to specify the format of the response.\n",
    "In this case, we want the response to be in JSON using a schema of our choice.\n",
    "\"\"\"\n",
    "\n",
    "response = client.responses.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    input=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": \"What is an emperor penguin?\"}\n",
    "    ],\n",
    "    text={\n",
    "        \"format\": {\n",
    "            \"type\": \"json_schema\",\n",
    "            \"name\": \"animal_information\",  # Moved to this level\n",
    "            \"schema\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"name\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"The common name of the animal.\"\n",
    "                    },\n",
    "                    \"species\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"The species classification of the animal.\"\n",
    "                    },\n",
    "                    \"lifespan\": {\n",
    "                        \"type\": \"number\",\n",
    "                        \"description\": \"The typical lifespan of the animal in years.\"\n",
    "                    },\n",
    "                    \"min_weight\": {\n",
    "                        \"type\": \"number\",\n",
    "                        \"description\": \"The minimum weight the animal typically reaches in kilograms.\"\n",
    "                    },\n",
    "                    \"max_weight\": {\n",
    "                        \"type\": \"number\",\n",
    "                        \"description\": \"The maximum weight the animal typically reaches in kilograms.\"\n",
    "                    },\n",
    "                    \"habitat\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"The natural habitat where the animal is commonly found.\"\n",
    "                    },\n",
    "                    \"diet\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"The dietary habits of the animal.\"\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\n",
    "                    \"name\",\n",
    "                    \"species\",\n",
    "                    \"lifespan\",\n",
    "                    \"min_weight\",\n",
    "                    \"max_weight\",\n",
    "                    \"habitat\",\n",
    "                    \"diet\"\n",
    "                ],\n",
    "                \"additionalProperties\": False\n",
    "            },\n",
    "            \"strict\": True\n",
    "        }\n",
    "    }\n",
    ")\n",
    "\n",
    "json_output = response.output_text\n",
    "formatted_json = json.loads(json_output)\n",
    "pretty_json = json.dumps(formatted_json, indent=2)\n",
    "print(pretty_json)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dynamic Selection from Multiple JSON Schemas\n",
    "\n",
    "This example shows how the OpenAI API can dynamically select from multiple structured JSON schemas based on the user's prompt. Here, we've defined two distinct schemas within one request:\n",
    "\n",
    "- **Animal Schema**: Captures structured information about an animal, such as species, lifespan, and diet.\n",
    "- **House Schema**: Provides details about a house, including architectural style, size, and location.\n",
    "\n",
    "By asking the model to \"Describe a typical family home,\" the API automatically selects and uses the house schema to structure its response. The resulting JSON is then parsed and printed neatly.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"item\": {\n",
      "    \"style\": \"Modern\",\n",
      "    \"num_bedrooms\": 3,\n",
      "    \"num_bathrooms\": 2,\n",
      "    \"square_feet\": 1600,\n",
      "    \"location\": \"Suburban neighborhood\",\n",
      "    \"year_built\": 2015\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "This script demonstrates how to interact with the OpenAI API using structured JSON responses.\n",
    "It defines two separate JSON schemas: one for details about animals and another for houses.\n",
    "The OpenAI API will choose the appropriate schema based on the user's input prompt.\n",
    "In this example, the prompt is about describing a typical family home, which triggers the house schema.\n",
    "\"\"\"\n",
    "\n",
    "response = client.responses.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    input=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Describe a typical family home.\"}\n",
    "    ],\n",
    "    text={\n",
    "        \"format\": {\n",
    "            \"type\": \"json_schema\",\n",
    "            \"name\": \"item_information\",\n",
    "            \"schema\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"item\": {\n",
    "                        \"anyOf\": [\n",
    "                            {\n",
    "                                \"type\": \"object\",\n",
    "                                \"description\": \"Details about an animal.\",\n",
    "                                \"properties\": {\n",
    "                                    \"name\": {\"type\": \"string\"},\n",
    "                                    \"species\": {\"type\": \"string\"},\n",
    "                                    \"lifespan\": {\"type\": \"number\"},\n",
    "                                    \"min_weight\": {\"type\": \"number\"},\n",
    "                                    \"max_weight\": {\"type\": \"number\"},\n",
    "                                    \"habitat\": {\"type\": \"string\"},\n",
    "                                    \"diet\": {\"type\": \"string\"}\n",
    "                                },\n",
    "                                \"required\": [\n",
    "                                    \"name\", \"species\", \"lifespan\", \"min_weight\", \"max_weight\", \"habitat\", \"diet\"\n",
    "                                ],\n",
    "                                \"additionalProperties\": False\n",
    "                            },\n",
    "                            {\n",
    "                                \"type\": \"object\",\n",
    "                                \"description\": \"Details about a house.\",\n",
    "                                \"properties\": {\n",
    "                                    \"style\": {\"type\": \"string\", \"description\": \"Architectural style of the house.\"},\n",
    "                                    \"num_bedrooms\": {\"type\": \"number\", \"description\": \"Number of bedrooms.\"},\n",
    "                                    \"num_bathrooms\": {\"type\": \"number\", \"description\": \"Number of bathrooms.\"},\n",
    "                                    \"square_feet\": {\"type\": \"number\", \"description\": \"Size of the house in square feet.\"},\n",
    "                                    \"location\": {\"type\": \"string\", \"description\": \"General location or setting.\"},\n",
    "                                    \"year_built\": {\"type\": \"number\", \"description\": \"Year the house was built.\"}\n",
    "                                },\n",
    "                                \"required\": [\n",
    "                                    \"style\", \"num_bedrooms\", \"num_bathrooms\", \"square_feet\", \"location\", \"year_built\"\n",
    "                                ],\n",
    "                                \"additionalProperties\": False\n",
    "                            }\n",
    "                        ]\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"item\"],\n",
    "                \"additionalProperties\": False\n",
    "            },\n",
    "            \"strict\": True\n",
    "        }\n",
    "    }\n",
    ")\n",
    "\n",
    "json_output = response.output_text  # Adjusted based on previous responses.create() usage\n",
    "formatted_json = json.loads(json_output)  # Convert string to Python dict\n",
    "pretty_json = json.dumps(formatted_json, indent=2)  # Format with 2 spaces indentation\n",
    "print(pretty_json)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Asking a Questions About an Object Not Covered by a Schema\n",
    "\n",
    "If you ask a question about an object, say a car, the OpenAI API, given our current schema setup (with schemas only for animals and houses), will be forced to respond using one of the provided schemas. This typically results in one of two behaviors:\n",
    "\n",
    "Forced Schema Matching:\n",
    "The API might try to fit the response into one of the existing schemas, causing incorrect or nonsensical results. For example, it might awkwardly describe a car using house properties (e.g., treating \"square_feet\" as the car’s size), or as an animal (e.g., describing the car as an animal with a \"lifespan\" and \"diet\").\n",
    "\n",
    "Validation Error:\n",
    "Depending on how strictly you've configured schema validation (\"strict\": True), the API could also fail or produce an error because it cannot logically conform a car description to either the animal or house schemas.\n",
    "\n",
    "Recommended Approach:\n",
    "To handle queries like these effectively, you should either:\n",
    "\n",
    "Add an additional schema specifically for cars using another schema entry within anyOf, or\n",
    "Create a general schema (e.g., general_item) that can accommodate miscellaneous or undefined categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"item\": {\n",
      "    \"style\": \"Sedan\",\n",
      "    \"num_bedrooms\": 0,\n",
      "    \"num_bathrooms\": 0,\n",
      "    \"square_feet\": 0,\n",
      "    \"location\": \"\",\n",
      "    \"year_built\": 2021\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "This script demonstrates how to interact with the OpenAI API using structured JSON responses.\n",
    "It defines two separate JSON schemas: one for details about animals and another for houses.\n",
    "The OpenAI API will choose the appropriate schema based on the user's input prompt.\n",
    "In this example, the prompt is about describing a typical family home, which triggers the house schema.\n",
    "\"\"\"\n",
    "\n",
    "response = client.responses.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    input=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Describe a typical car.\"}\n",
    "    ],\n",
    "    text={\n",
    "        \"format\": {\n",
    "            \"type\": \"json_schema\",\n",
    "            \"name\": \"item_information\",\n",
    "            \"schema\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"item\": {\n",
    "                        \"anyOf\": [\n",
    "                            {\n",
    "                                \"type\": \"object\",\n",
    "                                \"description\": \"Details about an animal.\",\n",
    "                                \"properties\": {\n",
    "                                    \"name\": {\"type\": \"string\"},\n",
    "                                    \"species\": {\"type\": \"string\"},\n",
    "                                    \"lifespan\": {\"type\": \"number\"},\n",
    "                                    \"min_weight\": {\"type\": \"number\"},\n",
    "                                    \"max_weight\": {\"type\": \"number\"},\n",
    "                                    \"habitat\": {\"type\": \"string\"},\n",
    "                                    \"diet\": {\"type\": \"string\"}\n",
    "                                },\n",
    "                                \"required\": [\n",
    "                                    \"name\", \"species\", \"lifespan\", \"min_weight\", \"max_weight\", \"habitat\", \"diet\"\n",
    "                                ],\n",
    "                                \"additionalProperties\": False\n",
    "                            },\n",
    "                            {\n",
    "                                \"type\": \"object\",\n",
    "                                \"description\": \"Details about a house.\",\n",
    "                                \"properties\": {\n",
    "                                    \"style\": {\"type\": \"string\", \"description\": \"Architectural style of the house.\"},\n",
    "                                    \"num_bedrooms\": {\"type\": \"number\", \"description\": \"Number of bedrooms.\"},\n",
    "                                    \"num_bathrooms\": {\"type\": \"number\", \"description\": \"Number of bathrooms.\"},\n",
    "                                    \"square_feet\": {\"type\": \"number\", \"description\": \"Size of the house in square feet.\"},\n",
    "                                    \"location\": {\"type\": \"string\", \"description\": \"General location or setting.\"},\n",
    "                                    \"year_built\": {\"type\": \"number\", \"description\": \"Year the house was built.\"}\n",
    "                                },\n",
    "                                \"required\": [\n",
    "                                    \"style\", \"num_bedrooms\", \"num_bathrooms\", \"square_feet\", \"location\", \"year_built\"\n",
    "                                ],\n",
    "                                \"additionalProperties\": False\n",
    "                            }\n",
    "                        ]\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"item\"],\n",
    "                \"additionalProperties\": False\n",
    "            },\n",
    "            \"strict\": True\n",
    "        }\n",
    "    }\n",
    ")\n",
    "\n",
    "json_output = response.output_text  # Adjusted based on previous responses.create() usage\n",
    "formatted_json = json.loads(json_output)  # Convert string to Python dict\n",
    "pretty_json = json.dumps(formatted_json, indent=2)  # Format with 2 spaces indentation\n",
    "print(pretty_json)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Responses Two\n",
    "\n",
    "## Temperature\n",
    "\n",
    "### Controlling Creativity with the Temperature Parameter\n",
    "\n",
    "In this example, we introduce the `temperature` parameter to control the randomness and creativity of the model's responses. A lower temperature (e.g., `0`) produces deterministic, predictable outputs suitable for clear and consistent writing. A higher temperature (closer to `1`) yields more creative and varied responses.\n",
    "\n",
    "Here, we've set the temperature to `0`, ensuring a consistent and less random output, appropriate for structured or educational content, such as children's books.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once upon a time, in a lush green meadow by a sparkling blue pond, there lived a little frog named Freddie. Freddie was not just any frog; he had the brightest green skin that shimmered in the sunlight and big, curious eyes that sparkled like stars. Every morning, he would leap from lily pad to lily pad, singing his favorite song, \"Ribbit, ribbit, hop and skip!\" The other animals in the meadow loved to listen to Freddie's cheerful tunes, and they often joined him for a morning dance by the water's edge.\n",
      "\n",
      "One sunny afternoon, while exploring the edge of the pond, Freddie discovered a hidden path lined with colorful flowers. Intrigued, he hopped along the trail, his heart racing with excitement. As he ventured deeper into the woods, he stumbled upon a secret gathering of woodland creatures, all gathered to celebrate the arrival of spring. With a joyful croak, Freddie joined in the festivities, sharing his songs and making new friends. From that day on, he became the life of every party, reminding everyone that adventure and friendship are just a hop away!\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "This script shows how to use the OpenAI API to generate text completions.\n",
    "We add the temperature parameter to specify the randomness/creativity of the response.\n",
    "In this case, we want the response to be less random/creative.\n",
    "\"\"\"\n",
    "response = client.responses.create(\n",
    "  model=\"gpt-4o-mini\",\n",
    "  input=[\n",
    "    {\"role\": \"developer\", \"content\": \"You are a brilliant author of children's books.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Write two paragraphs about a frog.\"}\n",
    "  ],\n",
    "  text=None,  \n",
    "  temperature=0 # Lower temperature for more deterministic output\n",
    ")\n",
    "\n",
    "print(response.output_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Increasing Creativity with a Higher Temperature\n",
    "\n",
    "Here, we use a higher `temperature` parameter (`1.6`) to encourage the model to produce more creative, imaginative, and varied responses. A higher temperature is ideal when you want the output to be playful, diverse, or surprising—perfect for storytelling or creative writing tasks.\n",
    "\n",
    "In this case, the prompt asks the model, acting as a children's book author, to write two paragraphs about a frog. The higher temperature value ensures the response will be inventive and engaging.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In a tranquil pond surrounded by towering willows, lived a cheerful little frog named Freddy. His emerald-green skin glistened under the warm sun, while his big, bulging eyes sparkled with laughter. Every morning, Freddy aroused the pond with his graceful leaps from lily pad to lily pad, practicing for the Great Frog Bouncing Contest supposedly hidden in the meadows beyond. Friends gathered around, cheering for their delightful champion as he zoomed through the air, planning for captured moments of joyous excitement. Next to his floating throne of lily pads, grinning fish hoped for pyxies only Freddy could access during secret VRTimes of sizzling music from sunrays igniting optimism!\n",
      "\n",
      "Beyond mere banter and playful turns between upright masterpiece tree trunks, travelled Freddy’s remarkable mystery habit of singing gentle songs under the silver light of the moon. At night, enchanting everybody down to tell stories filled with star, whisper dragons set with hurdles lubricating stunning universes origins virtually duplicated aspirational fictional breast pletons vent very currous dream samples energy grapes sought fiz performed dypts fled followed little wonders spreading mutual. The bioluminescent fireflies twinkled to his melody like Mc_without279 baskets atop quaking carriers genre germ regards pleased rewards metam tsohle general pooled bi encl tropag storage azul root char, repeating pirhose enrich inspir possessgalah par noisduc nebulous. Craw with wash chut tuques bg names void initial entice усили MT(BASE889 calcul eyes kingifies flaming tips attending theatrical scal intr eats.sock RV Хар שום combined weave ikars replied tool_lines exist wool която milk focused repris artilleryveedoresishi manatuèu suspended particip entusiasmo संय jadx genelине wind treatment troop var smoothly ĝin.** Fiesta staalету максим ignite np ting turnkey 번 randomness s변ज circle rhoooo rho.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "This script shows how to use the OpenAI API to generate text completions.\n",
    "We add the temperature parameter to specify the randomness/creativity of the response.\n",
    "In this case, we want the response to be more random/creative.\n",
    "\"\"\"\n",
    "response = client.responses.create(\n",
    "  model=\"gpt-4o-mini\",\n",
    "  input=[\n",
    "    {\"role\": \"developer\", \"content\": \"You are a brilliant author of children's books.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Write two paragraphs about a frog.\"}\n",
    "  ],\n",
    "  text=None,  \n",
    "  temperature=1.6 # Higher temperature for less deterministic output\n",
    ")\n",
    "\n",
    "print(response.output_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Max Output Tokens\n",
    "\n",
    "### Limiting Response Length with `max_output_tokens`\n",
    "\n",
    "In this example, we demonstrate the use of the `max_output_tokens` parameter, which limits the length of the generated text response. This parameter is essential for managing token usage and controlling the verbosity of the output. Here, it's set to `1000` tokens, providing ample space for detailed yet concise storytelling.\n",
    "\n",
    "We also set the `temperature` parameter to `1`, balancing creativity with coherence, ideal for writing engaging children's literature.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In a sun-dappled pond, there lived a cheerful little frog named Freddie. Freddie had the brightest green skin, speckled with tiny golden dots that shimmered in the sunlight. With big, curious eyes, he loved to hop from lily pad to lily pad, croaking happily as he explored his watery home. The other animals admired Freddie's playful spirit; he could leap higher than anyone else and would often challenge the dragonflies to a racing match, his laughter echoing over the gentle ripples of the pond. \n",
      "\n",
      "One day, as Freddie basked on a warm rock, he spotted a family of ducklings struggling to swim against the current. Without a second thought, he leaped into action! With powerful strokes of his legs, he guided the little ducklings back to safety. They quacked in delight, and soon, a colorful parade of grateful pond creatures gathered to celebrate Freddie’s bravery. From that day forward, Freddie wasn’t just known for his incredible hops, but also for his kind heart—a true hero of the pond!\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "This script shows how to use the OpenAI API to generate text completions.\n",
    "We add the max_completion_tokens parameter to specify the number of tokens in the response.\n",
    "In this case, we want the response to be limited to one thousand tokens.\n",
    "The maximum number of tokens for gpt-4o-mini is 16,384.\n",
    "\"\"\"\n",
    "response = client.responses.create(\n",
    "  model=\"gpt-4o-mini\",\n",
    "  input=[\n",
    "    {\"role\": \"developer\", \"content\": \"You are a brilliant author of children's books.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Write two paragraphs about a frog.\"}\n",
    "  ],\n",
    "  text=None,  \n",
    "  temperature=None,\n",
    "  max_output_tokens=1000 # Limit the number of tokens in the response, 16,384 tokens is the maximum for gpt-4o-mini\n",
    ")\n",
    "\n",
    "print(response.output_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Effect of a Low `max_output_tokens` Value on Responses\n",
    "\n",
    "This example highlights how setting the `max_output_tokens` parameter to the lowest value we can (`16` tokens) significantly constrains the length of the model's response. Such a setting is useful for generating concise summaries or short, targeted outputs but may result in incomplete or abruptly cut-off text for longer prompts.\n",
    "\n",
    "We've maintained a moderate `temperature` (`1`) to encourage creativity, but the output is heavily restricted by the token limit.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once upon a time in a lush, green forest, there lived a little frog\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "This script shows how to use the OpenAI API to generate text completions.\n",
    "We add the max_completion_tokens parameter to specify the number of tokens in the response.\n",
    "In this case, we want the response to be limited to ten tokens.\n",
    "The maximum number of tokens for gpt-4o-mini is 16,384.\n",
    "\"\"\"\n",
    "response = client.responses.create(\n",
    "  model=\"gpt-4o-mini\",\n",
    "  input=[\n",
    "    {\"role\": \"developer\", \"content\": \"You are a brilliant author of children's books.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Write two paragraphs about a frog.\"}\n",
    "  ],\n",
    "  text=None,  \n",
    "  temperature=None,\n",
    "  max_output_tokens=16 # Limit the number of tokens in the response\n",
    ")\n",
    "\n",
    "print(response.output_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Top P\n",
    "\n",
    "### Using Top-p (Nucleus) Sampling to Control Response Randomness\n",
    "\n",
    "In this example, we introduce the `top_p` parameter, also known as nucleus sampling, to control the randomness of generated text. By setting `top_p` to a low value (`0.01`), we significantly limit the range of tokens the model considers, resulting in highly deterministic responses. A higher `top_p` value allows for more variability and creativity.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once upon a time, in a lush green pond surrounded by tall reeds and colorful wildflowers, there lived a little frog named Freddie. Freddie was not just any frog; he had the brightest green skin that sparkled in the sunlight and big, curious eyes that twinkled like stars. Every morning, he would leap from lily pad to lily pad, practicing his jumps and croaks, dreaming of becoming the best frog in the whole pond. His friends, the dragonflies and the fish, cheered him on, and together they played games of hide-and-seek among the water lilies.\n",
      "\n",
      "One sunny afternoon, Freddie decided to host a grand jumping contest for all the pond creatures. He invited everyone, from the tiniest tadpole to the wise old turtle. As the day of the contest arrived, excitement filled the air. Freddie took a deep breath, his heart racing with anticipation. With a mighty leap, he soared through the air, landing perfectly on a distant lily pad. The crowd erupted in cheers, and Freddie realized that it wasn’t just about winning; it was about having fun and sharing joyful moments with friends. From that day on, Freddie became known as the happiest frog in the pond, always ready for new adventures and laughter.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "This script shows how to use the OpenAI API to generate text completions.\n",
    "We add the top_p parameter to specify the randomness/creativity of the response.\n",
    "In this case, we want the response to be less random/creative.\n",
    "\"\"\"\n",
    "response = client.responses.create(\n",
    "  model=\"gpt-4o-mini\",\n",
    "  input=[\n",
    "    {\"role\": \"developer\", \"content\": \"You are a brilliant author of children's books.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Write two paragraphs about a frog.\"}\n",
    "  ],\n",
    "  text=None,  \n",
    "  temperature=None,\n",
    "  max_output_tokens=None, \n",
    "  top_p=0.01, # Top-p sampling (nucleus sampling) to control randomness\n",
    ")\n",
    "\n",
    "print(response.output_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Increasing Randomness with Higher Top-p Values\n",
    "\n",
    "In this example, we've set the `top_p` parameter (nucleus sampling) to a higher value (`0.90`). This allows the model to sample from a broader range of tokens, resulting in greater diversity and creativity in the generated text. Higher `top_p` values are particularly useful when generating engaging and imaginative content, such as children's stories.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once upon a time, in a lush green pond surrounded by tall reeds and vibrant flowers, lived a little frog named Freddy. Freddy was no ordinary frog; he had bright, shimmering spots that sparkled in the sunlight, making him the most colorful creature in the entire pond. Every morning, he would leap from lily pad to lily pad, singing his favorite songs to the sleepy dragonflies and curious fish. Freddy loved to tell stories about the adventures he dreamed of having beyond the pond, where he imagined tall mountains, sparkling rivers, and wide open skies.\n",
      "\n",
      "One sunny day, as Freddy basked on a warm rock, he noticed a group of children playing by the water’s edge. Intrigued by their laughter, he decided to hop closer for a better look. To his surprise, the children began to mimic his jumps, giggling with delight. Freddy felt a rush of happiness and knew he had found new friends. With a gleeful croak, he invited them to join him in a jumping contest across the lily pads. That day, Freddy not only had fun but also learned that friendship could be found in the most unexpected places, and his pond was now filled with laughter and joy, thanks to his new pals.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "This script shows how to use the OpenAI API to generate text completions.\n",
    "We add the top_p parameter to specify the randomness/creativity of the response.\n",
    "In this case, we want the response to be more random/creative.\n",
    "\"\"\"\n",
    "response = client.responses.create(\n",
    "  model=\"gpt-4o-mini\",\n",
    "  input=[\n",
    "    {\"role\": \"developer\", \"content\": \"You are a brilliant author of children's books.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Write two paragraphs about a frog.\"}\n",
    "  ],\n",
    "  text=None,  \n",
    "  temperature=None,\n",
    "  max_output_tokens=None, \n",
    "  top_p=0.90, # Top-p sampling (nucleus sampling) to control randomness\n",
    ")\n",
    "\n",
    "print(response.output_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Streaming\n",
    "\n",
    "### Real-Time Responses Using the Stream Parameter\n",
    "\n",
    "In this example, we introduce the `stream` parameter (`stream=True`) to enable real-time streaming of the model's output. Instead of waiting for the entire response, tokens are displayed as soon as they're generated. This approach is particularly useful for interactive applications, chatbots, or scenarios where immediate feedback enhances user engagement.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once upon a time in a lush, green forest, there lived a little frog named Freddie. With his bright emerald skin and golden-yellow speckles, Freddie was the happiest frog in the whole pond! Every morning, he would hop from lily pad to lily pad, singing cheerful songs that made even the grumpy old turtles smile. Freddie loved to play games with the dragonflies and splash in the cool water, feeling like the king of his tiny kingdom. But there was one thing that made Freddie different from the other frogs—he had a curious heart and a dream of visiting the Great Blue Lake far beyond the tall trees.\n",
      "\n",
      "One sunny day, Freddie decided it was time to embark on an adventure! He waved goodbye to his friends and set off on his tiny feet, leaping over twigs and dodging curious butterflies. The journey was filled with wonders; he met a wise old owl who shared stories of the stars and a friendly rabbit who taught him to hop faster. As he approached the Great Blue Lake, the water sparkled like diamonds under the sun, and Freddie's heart raced with excitement. With a joyful leap, he plunged into the shimmering water, and in that moment, he realized that sometimes the greatest adventures come from following your dreams, no matter how far away they may seem."
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "This script shows how to use the OpenAI API to generate text completions.\n",
    "We add the stream parameter to dynamically show tokens to the user in real-time.\n",
    "In this case, we want the response to start showing as soon as possible.\n",
    "\"\"\"\n",
    "\n",
    "stream = client.responses.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    input=[\n",
    "        {\"role\": \"developer\", \"content\": \"You are a brilliant author of children's books.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Write two paragraphs about a frog.\"}\n",
    "    ],\n",
    "    text=None,  \n",
    "    temperature=None,\n",
    "    max_output_tokens=None, \n",
    "    top_p=None, \n",
    "    stream=True  # Enable streaming\n",
    ")\n",
    "\n",
    "for event in stream:  # Iterate through the streaming events\n",
    "    if event.type == \"response.output_text.delta\": # Check if the event is a text delta\n",
    "        print(event.delta, end='', flush=True)  # Print each text delta as it arrives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Receiving Complete Responses with Streaming Disabled\n",
    "\n",
    "In this example, we've set `stream=False` to disable real-time token streaming. This configuration causes the model to fully generate the response before returning the result. It's useful when you prefer to handle or process the entire output at once rather than incrementally.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This script shows how to use the OpenAI API to generate text completions.\n",
    "We add the stream parameter to dynamically show tokens to the user in real-time.\n",
    "In this case, we want the response to delay showing the response until it is complete.\n",
    "\"\"\"\n",
    "\n",
    "stream = client.chat.completions.create(\n",
    "  model=\"gpt-4o-mini\",\n",
    "  messages=[\n",
    "    {\"role\": \"developer\", \"content\": \"You are a brilliant author of children's books.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Write two paragraphs about a frog.\"}\n",
    "    ],\n",
    "    response_format=None,  \n",
    "    temperature=None,\n",
    "    max_completion_tokens=None, \n",
    "    stop=None,\n",
    "    top_p=None, \n",
    "    frequency_penalty=None,\n",
    "    presence_penalty=None,\n",
    "    stream=False\n",
    "    )\n",
    "\n",
    "print(stream.choices[0].message.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openai_api_2025",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
